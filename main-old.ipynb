{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_xml(data):\n",
    "    start_tag = \"<diagram\"\n",
    "    end_tag = \"</diagram>\"\n",
    "    start_index = data.find(start_tag)\n",
    "    end_index = data.find(end_tag) + len(end_tag)\n",
    "    xml_data = data[start_index:end_index]\n",
    "    return xml_data\n",
    "\n",
    "# Extract data from XML\n",
    "def get_xml_cell_data(mx_cell):\n",
    "    vertex = mx_cell.get(\"vertex\", '')\n",
    "    edge = mx_cell.get(\"edge\", '')\n",
    "    id = mx_cell.get(\"id\", '')\n",
    "    parent = html.unescape(mx_cell.get(\"parent\", ''))\n",
    "    source = html.unescape(mx_cell.get(\"source\", ''))\n",
    "    target = html.unescape(mx_cell.get(\"target\", ''))\n",
    "    value = html.unescape(mx_cell.get(\"value\", '')).replace(\"Â \", \" \")\n",
    "    styles = html.unescape(mx_cell.get(\"style\", '')).split(\";\")\n",
    "    return vertex, edge, id, parent, source, target, value, styles\n",
    "\n",
    "# compile block\n",
    "def abstract_block_compiler(shape, id, value):\n",
    "    return {\n",
    "        'mode': shape,\n",
    "        'ins': [],\n",
    "        'outs': [],\n",
    "        'id': id,\n",
    "        'value': value,\n",
    "        'msg': ''\n",
    "    }\n",
    "\n",
    "def search_in_list(list, keyword):\n",
    "    for item in list:\n",
    "        if keyword in item:\n",
    "            return item\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile all shapes\n",
    "def compile_shapes(root):\n",
    "    blocks = {}\n",
    "    edges = {}\n",
    "    edges_msg = {}\n",
    "    the_start_block_id = None\n",
    "    for mx_cell in root.findall(\".//mxCell\"):\n",
    "        vertex, edge, id, parent, source, target, value, styles = get_xml_cell_data(mx_cell)\n",
    "        # data = {}\n",
    "\n",
    "        # edgelabel_check = search_in_list(styles, \"edgeLabel\")\n",
    "        # edgestyle_check = search_in_list(styles, \"edgeStyle\")\n",
    "        shape_check = search_in_list(styles, \"shape\")\n",
    "        style_check = search_in_list(styles, \"absoluteArcSize\")\n",
    "\n",
    "        # It's shape\n",
    "        if shape_check != False or style_check != False:\n",
    "\n",
    "            shape = shape_check if shape_check != False else style_check\n",
    "            # data\n",
    "            if shape == 'shape=parallelogram': shape = 'input'\n",
    "            # display\n",
    "            elif shape == \"shape=mxgraph.flowchart.display\": shape = 'display'\n",
    "            # start\n",
    "            elif shape == \"shape=mxgraph.flowchart.start_2\":\n",
    "                shape = 'start'\n",
    "                the_start_block_id = id\n",
    "            # stored_data\n",
    "            elif shape == \"shape=mxgraph.flowchart.stored_data\": shape = 'stored_data'\n",
    "            # decision\n",
    "            elif shape == \"shape=mxgraph.flowchart.decision\": shape = 'decision'\n",
    "            # process\n",
    "            elif shape == \"absoluteArcSize=1\": shape = 'process'\n",
    "\n",
    "            blocks[id] = abstract_block_compiler(shape, id, value)\n",
    "\n",
    "        # It's edge or sth\n",
    "        else:\n",
    "            msg = search_in_list(styles, \"edgeLabel\")\n",
    "            if msg != False: edges_msg[id] = {'parent':parent, 'id':id, 'value':value}\n",
    "            elif edge == '1': edges[id] = {'id':id, 'source':source, 'target':target, 'value':''}\n",
    "            \n",
    "        continue\n",
    "\n",
    "    # fuse edges with their messages\n",
    "    for msg in edges_msg:\n",
    "        target_edge_id = edges_msg[msg]['parent']\n",
    "        edge_msg = edges_msg[msg]['value']\n",
    "        edges[target_edge_id]['value'] = edge_msg\n",
    "\n",
    "    # fuse blocks with their edges\n",
    "    for edge in edges:\n",
    "        this_edge = edges[edge]\n",
    "        the_source_block = blocks[this_edge['source']]\n",
    "        the_target_block = blocks[this_edge['target']]\n",
    "\n",
    "        # Handle Decision Edges (outs)\n",
    "        if the_source_block[\"mode\"] == \"decision\": the_source_block['outs'].append(the_target_block)\n",
    "        \n",
    "        # For All (ins)\n",
    "        the_target_block['ins'].append(this_edge)\n",
    "\n",
    "    return blocks, the_start_block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the tail from the starting block\n",
    "def generate_flow(init_block_id, blocks):\n",
    "    block_flow = []\n",
    "    block_flow.append(blocks[init_block_id])\n",
    "    for i in blocks:\n",
    "        for block in blocks:\n",
    "            this_block = blocks[block]\n",
    "            last_block_flow = block_flow[-1]\n",
    "            sources_of_ins = np.array([thein['source'] for thein in this_block['ins']])\n",
    "            is_ther_any_match = np.where(sources_of_ins == last_block_flow['id'])[0]\n",
    "            if is_ther_any_match.size > 0: block_flow.append(this_block)\n",
    "    return block_flow\n",
    "\n",
    "def detect_loop(init_block_id, blocks):\n",
    "    the_flow = generate_flow(init_block_id, blocks)\n",
    "    the_flow.pop(0)\n",
    "    loop_found = False\n",
    "    for block in the_flow:\n",
    "        false_option = block.get('false', False)\n",
    "        if init_block_id == block['id']: loop_found = True\n",
    "        elif false_option != False and false_option['id'] == init_block_id: loop_found = True\n",
    "    return loop_found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_block(suffix, block):\n",
    "    lines = ''\n",
    "    lines += suffix + block['value']\n",
    "    lines += \" = \"\n",
    "    lines += \"input('\"+block['msg']+\"')\"\n",
    "    lines += \"\\n\"\n",
    "    return lines\n",
    "\n",
    "def process_block(suffix, block):\n",
    "    lines = ''\n",
    "    lines += suffix+block['value']\n",
    "    lines += \"\\n\"\n",
    "    return lines\n",
    "\n",
    "def display_block(suffix, block):\n",
    "    lines = ''\n",
    "    lines += suffix+\"print(\"\n",
    "    lines += block['value']\n",
    "    lines += \")\\n\"\n",
    "    return lines\n",
    "\n",
    "def stored_data_block(suffix, block):\n",
    "    lines = ''\n",
    "    lines += suffix+block['msg']\n",
    "    lines += \" = np.array([\"\n",
    "    for item in block['value'].split(','): lines += '\"'+item.strip()+'\", '\n",
    "    lines += \"])\\n\"\n",
    "    return lines\n",
    "\n",
    "def decision_block(suffix, block, dealing_decisions):\n",
    "    global blocks\n",
    "    lines = ''\n",
    "    dealing_decisions.append(block['id'])\n",
    "    # loop_check = detect_loop(block['false']['id'], blocks)\n",
    "    # if loop_check == False:\n",
    "    #     lines += suffix+\"if \"\n",
    "    #     lines += block['value']\n",
    "    #     lines += \":\\n\"\n",
    "    # else:\n",
    "    #     lines += suffix+\"while (\"\n",
    "    #     lines += block['value']\n",
    "    #     lines += \"):\\n\"\n",
    "    # suffix+=\"\\t\"\n",
    "    return lines, dealing_decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_block(flow, dealing_decisions, suffix=''):\n",
    "    lines = ''\n",
    "    for block in flow:\n",
    "        if block['mode'] == 'input': newlines = input_block(suffix, block)\n",
    "        elif block['mode'] == 'process': newlines = process_block(suffix, block)\n",
    "        elif block['mode'] == 'display': newlines = display_block(suffix, block)\n",
    "        elif block['mode'] == 'stored_data': newlines = stored_data_block(suffix, block)\n",
    "        elif block['mode'] == 'decision': newlines, dealing_decisions = decision_block(suffix, block, dealing_decisions)\n",
    "    lines += newlines\n",
    "    return lines, dealing_decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_compiler(blocks, the_start_block_id):\n",
    "    lines = ''\n",
    "    lines += blocks[the_start_block_id]['value']\n",
    "    lines += \"\\n\"\n",
    "            \n",
    "    dealing_decisions = []\n",
    "    \n",
    "    newlines, dealing_decisions = compile_block(\n",
    "        generate_flow(the_start_block_id, blocks),\n",
    "        dealing_decisions\n",
    "    )\n",
    "    lines += newlines\n",
    "\n",
    "    # for this_else in reversed(dealing_decisions):\n",
    "    #     thesuffix = \"\"\n",
    "    #     for i in range(len(dealing_decisions)): thesuffix += \"\\t\"\n",
    "    #     lines += \"else:\\n\"\n",
    "    #     dealing_decisions.pop()\n",
    "    #     newlines, dealing_decisions = compile_block(\n",
    "    #         generate_flow(blocks[this_else]['false']['id'], blocks),\n",
    "    #         dealing_decisions,\n",
    "    #         suffix=thesuffix,\n",
    "    #     )\n",
    "    #     lines += newlines\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21686/640081214.py:10: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  is_ther_any_match = np.where(sources_of_ins == last_block_flow['id'])[0]\n",
      "/tmp/ipykernel_21686/640081214.py:10: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  is_ther_any_match = np.where(sources_of_ins == last_block_flow['id'])[0]\n",
      "/tmp/ipykernel_21686/640081214.py:10: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  is_ther_any_match = np.where(sources_of_ins == last_block_flow['id'])[0]\n",
      "/tmp/ipykernel_21686/640081214.py:10: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  is_ther_any_match = np.where(sources_of_ins == last_block_flow['id'])[0]\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "# Load variables from .env file into the environment\n",
    "load_dotenv()\n",
    "\n",
    "def convert():\n",
    "    print(\"convert\")\n",
    "    # 1. Read the Draw.io file\n",
    "    with open(os.getenv(\"SRC_FILE\"), \"r\") as file:\n",
    "        drawio_data = file.read()\n",
    "\n",
    "    # 2. Extract the XML data\n",
    "    xml_data = prepare_xml(drawio_data)\n",
    "    \n",
    "    if len(os.getenv(\"DEST_XML_FILE\")) >= 0:\n",
    "        with open(os.getenv(\"DEST_XML_FILE\"), \"w\") as file: file.writelines(xml_data)\n",
    "    \n",
    "    # 3. Process the XML data\n",
    "    root = ET.fromstring(xml_data)\n",
    "    blocks, the_start_block_id = compile_shapes(root)\n",
    "    lines = flow_compiler(blocks, the_start_block_id)\n",
    "    \n",
    "    with open(os.getenv(\"DEST_FILE\"), \"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "# Define the function to be executed when a change occurs\n",
    "def on_file_change():\n",
    "    print(\"File changed!\")\n",
    "\n",
    "# Define the event handler class\n",
    "class FileChangeHandler(FileSystemEventHandler):\n",
    "    def on_modified(self, event):\n",
    "        # Call the function when a modification event occurs\n",
    "        convert()\n",
    "\n",
    "# Create an observer and attach the event handler\n",
    "observer = Observer()\n",
    "observer.schedule(FileChangeHandler(), path=os.getenv(\"SRC_FILE\"), recursive=False)\n",
    "\n",
    "# Start the observer\n",
    "observer.start()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    # Stop the observer if interrupted\n",
    "    observer.stop()\n",
    "\n",
    "# Wait until the observer thread completes its execution\n",
    "observer.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
